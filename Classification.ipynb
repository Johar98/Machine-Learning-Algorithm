{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsd3mQ+s5RfOW3vWXLT/yR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johar98/Machine-Learning-Algorithm/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BYNVuoGbmof"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYNLcJ2Yb1Yz"
      },
      "source": [
        "CSV_COLUMN_NAME = ['SepalLength','SepalWidth','PetalLength','PetalWidth','Species'] #data set headers for the columns / properties\n",
        "SPECIES = ['Setosa','Versicolor','Virginica'] # plant name"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBc2F-dcdCqA"
      },
      "source": [
        "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "#for training our model\n",
        "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "#for testing\n",
        "#here we use keras(a module inside of tensorflow) to grab our datasets and read them into a pandas dataframe"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmRi6HBSpUP8",
        "outputId": "46158f4d-a49d-4fe5-d2f1-c0ca3e21d02f"
      },
      "source": [
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAME, header=0) #load train\n",
        "#row 0 is header\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAME, header=0) #load test\n",
        "print(train.head())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
            "0          6.4         2.8          5.6         2.2        2\n",
            "1          5.0         2.3          3.3         1.0        1\n",
            "2          4.9         2.5          4.5         1.7        2\n",
            "3          4.9         3.1          1.5         0.1        0\n",
            "4          5.7         3.8          1.7         0.3        0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lva0JZOQxdHL",
        "outputId": "d010d7dc-a466-4a95-a061-01e18e9249ce"
      },
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')\n",
        "print(train.head())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
            "0          6.4         2.8          5.6         2.2\n",
            "1          5.0         2.3          3.3         1.0\n",
            "2          4.9         2.5          4.5         1.7\n",
            "3          4.9         3.1          1.5         0.1\n",
            "4          5.7         3.8          1.7         0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRFRNx5nzFpe"
      },
      "source": [
        "def input_fn(features, labels,training=True, batch_size=256):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "  if training: #shuffle and repeat if you are in training mode\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "  return dataset.batch(batch_size)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G2khXyL0gdc",
        "outputId": "61f0f85a-82e7-4f70-99f2-cbb187868a60"
      },
      "source": [
        "my_feature_columns = []\n",
        "for key in train.keys():# give us all the columns\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key)) #current key = random key\n",
        "print(my_feature_columns)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS6YufwMBw6f",
        "outputId": "299636a4-68d1-4a85-be23-c12cd250c3e2"
      },
      "source": [
        "classifier = tf.estimator.DNNClassifier( #.estimator = store/build pre made model from tf\n",
        "    feature_columns=my_feature_columns, #two hidden layers of 30 and 10 nodes respectively use to build an artichecter of neural network\n",
        "    hidden_units=[30,10], # 30 = 1st node , 10 = 2nd node\n",
        "    n_classes= 3) # the model must choose between 3 classes"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpu1nd1546\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpu1nd1546', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tQ0Dq0VEMHS",
        "outputId": "129135d9-41cc-4319-c7eb-30f0c82bd4a5"
      },
      "source": [
        "classifier.train(\n",
        "    input_fn=lambda:input_fn(train, train_y, training = True),\n",
        "     steps=5000)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpu1nd1546/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 1.8089938, step = 0\n",
            "INFO:tensorflow:global_step/sec: 482.192\n",
            "INFO:tensorflow:loss = 1.3152995, step = 100 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.667\n",
            "INFO:tensorflow:loss = 1.1653509, step = 200 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.957\n",
            "INFO:tensorflow:loss = 1.0516269, step = 300 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 629.274\n",
            "INFO:tensorflow:loss = 0.97598577, step = 400 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.539\n",
            "INFO:tensorflow:loss = 0.953057, step = 500 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.051\n",
            "INFO:tensorflow:loss = 0.92117214, step = 600 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.902\n",
            "INFO:tensorflow:loss = 0.8914382, step = 700 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.706\n",
            "INFO:tensorflow:loss = 0.8534777, step = 800 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.776\n",
            "INFO:tensorflow:loss = 0.838351, step = 900 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.286\n",
            "INFO:tensorflow:loss = 0.82308865, step = 1000 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.155\n",
            "INFO:tensorflow:loss = 0.80167353, step = 1100 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.008\n",
            "INFO:tensorflow:loss = 0.8061476, step = 1200 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.982\n",
            "INFO:tensorflow:loss = 0.7994015, step = 1300 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.404\n",
            "INFO:tensorflow:loss = 0.7581957, step = 1400 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.764\n",
            "INFO:tensorflow:loss = 0.7638471, step = 1500 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.859\n",
            "INFO:tensorflow:loss = 0.762493, step = 1600 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 593.145\n",
            "INFO:tensorflow:loss = 0.7597723, step = 1700 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.897\n",
            "INFO:tensorflow:loss = 0.7458884, step = 1800 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.867\n",
            "INFO:tensorflow:loss = 0.7375401, step = 1900 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.947\n",
            "INFO:tensorflow:loss = 0.7234063, step = 2000 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.078\n",
            "INFO:tensorflow:loss = 0.7297965, step = 2100 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.204\n",
            "INFO:tensorflow:loss = 0.7049516, step = 2200 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 605.06\n",
            "INFO:tensorflow:loss = 0.706643, step = 2300 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.432\n",
            "INFO:tensorflow:loss = 0.7126088, step = 2400 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.542\n",
            "INFO:tensorflow:loss = 0.700289, step = 2500 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 558.328\n",
            "INFO:tensorflow:loss = 0.6918218, step = 2600 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 647\n",
            "INFO:tensorflow:loss = 0.68514705, step = 2700 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.312\n",
            "INFO:tensorflow:loss = 0.67108065, step = 2800 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.921\n",
            "INFO:tensorflow:loss = 0.67705315, step = 2900 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.948\n",
            "INFO:tensorflow:loss = 0.66394967, step = 3000 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.215\n",
            "INFO:tensorflow:loss = 0.6773754, step = 3100 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.911\n",
            "INFO:tensorflow:loss = 0.664227, step = 3200 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.447\n",
            "INFO:tensorflow:loss = 0.6579634, step = 3300 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.636\n",
            "INFO:tensorflow:loss = 0.66074014, step = 3400 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.089\n",
            "INFO:tensorflow:loss = 0.65452236, step = 3500 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.78\n",
            "INFO:tensorflow:loss = 0.6524248, step = 3600 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.315\n",
            "INFO:tensorflow:loss = 0.6441958, step = 3700 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.003\n",
            "INFO:tensorflow:loss = 0.6404027, step = 3800 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.014\n",
            "INFO:tensorflow:loss = 0.6321139, step = 3900 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.281\n",
            "INFO:tensorflow:loss = 0.6490603, step = 4000 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.13\n",
            "INFO:tensorflow:loss = 0.61985403, step = 4100 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.514\n",
            "INFO:tensorflow:loss = 0.6256431, step = 4200 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 601.257\n",
            "INFO:tensorflow:loss = 0.6271709, step = 4300 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.22\n",
            "INFO:tensorflow:loss = 0.61209774, step = 4400 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.88\n",
            "INFO:tensorflow:loss = 0.6129247, step = 4500 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.685\n",
            "INFO:tensorflow:loss = 0.59157735, step = 4600 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 595.533\n",
            "INFO:tensorflow:loss = 0.6097395, step = 4700 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.849\n",
            "INFO:tensorflow:loss = 0.59853786, step = 4800 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.991\n",
            "INFO:tensorflow:loss = 0.59372574, step = 4900 (0.164 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpu1nd1546/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.60649663.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f6726d5a050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaAIY9iuHL4l",
        "outputId": "45c2bc2b-edce-451a-9857-d7a51955843a"
      },
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda:input_fn(test,test_y,training=False))\n",
        "print('\\n Test set accuracy:{accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-03-20T17:25:33Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpu1nd1546/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.20449s\n",
            "INFO:tensorflow:Finished evaluation at 2021-03-20-17:25:33\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.53333336, average_loss = 0.7090868, global_step = 5000, loss = 0.7090868\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpu1nd1546/model.ckpt-5000\n",
            "\n",
            " Test set accuracy:0.533\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCYHWuXpJLaj",
        "outputId": "74481407-b4a6-4e3e-a956-6f68ae4f21b7"
      },
      "source": [
        "def input_fn(features, batch_size=256): #convert the input to a dataset without labels\n",
        "  return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "features= ['SepalLength','SepalWidth','PetalLength','PetalWidth'] #these are the feature\n",
        "predict = {}\n",
        "print(\"Please type numeric values as prompted\")\n",
        "for feature in features:# for each feature we are going to wait for valid respond once we get some valid response \n",
        "  valid = True          # then we will add that to dictonary\n",
        "  while valid :\n",
        "    val = input(feature + \":\")\n",
        "    if not val.isdigit():valid=False\n",
        "  predict[feature]=[float(val)] # list of value what we have // also show input function to put data of leaf\n",
        "predictions = classifier.predict(input_fn=lambda:input_fn(predict))\n",
        "for pred_dict in predictions:\n",
        "  print(pred_dict)\n",
        "  class_id = pred_dict['class_ids'][0]\n",
        "  probability = pred_dict['probabilities'][class_id]\n",
        "  print('prediction is \"{}\" ({:.1f}'.format(\n",
        "      SPECIES[class_id],100 * probability))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please type numeric values as prompted\n",
            "SepalLength:1.2\n",
            "SepalWidth:2.1\n",
            "PetalLength:2.1\n",
            "PetalWidth:1.1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpu1nd1546/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "{'logits': array([-0.65726596, -0.24471274, -0.11067313], dtype=float32), 'probabilities': array([0.23595884, 0.35645592, 0.4075853 ], dtype=float32), 'class_ids': array([2]), 'classes': array([b'2'], dtype=object), 'all_class_ids': array([0, 1, 2], dtype=int32), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
            "prediction is \"Virginica\" (40.8\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}